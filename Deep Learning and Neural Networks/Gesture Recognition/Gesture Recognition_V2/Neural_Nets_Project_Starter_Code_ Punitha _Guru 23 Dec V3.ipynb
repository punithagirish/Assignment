{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NuIfpo8wza4X"
   },
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/project/PROJECT\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/disks/user/project/PROJECT/\n",
    "#!rm -rf model_init_conv_lstm_2019-12-2311_42_08.483251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: livelossplot in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (0.4.1)\n",
      "Requirement already satisfied: notebook in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from livelossplot) (5.7.0)\n",
      "Requirement already satisfied: matplotlib in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from livelossplot) (3.0.2)\n",
      "Requirement already satisfied: tornado>=4 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from notebook->livelossplot) (5.0.2)\n",
      "Requirement already satisfied: nbconvert in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from notebook->livelossplot) (5.3.1)\n",
      "Requirement already satisfied: Send2Trash in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from notebook->livelossplot) (1.5.0)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from notebook->livelossplot) (4.3.2)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from notebook->livelossplot) (5.2.3)\n",
      "Requirement already satisfied: ipykernel in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from notebook->livelossplot) (4.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from notebook->livelossplot) (0.8.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from notebook->livelossplot) (17.0.0)\n",
      "Requirement already satisfied: nbformat in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from notebook->livelossplot) (4.4.0)\n",
      "Requirement already satisfied: prometheus-client in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from notebook->livelossplot) (0.4.0)\n",
      "Requirement already satisfied: ipython-genutils in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from notebook->livelossplot) (0.2.0)\n",
      "Requirement already satisfied: jinja2 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from notebook->livelossplot) (2.10)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from notebook->livelossplot) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from matplotlib->livelossplot) (1.14.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from matplotlib->livelossplot) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from matplotlib->livelossplot) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from matplotlib->livelossplot) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from matplotlib->livelossplot) (2.7.3)\n",
      "Requirement already satisfied: mistune>=0.7.4 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from nbconvert->notebook->livelossplot) (0.8.3)\n",
      "Requirement already satisfied: pygments in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from nbconvert->notebook->livelossplot) (2.2.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from nbconvert->notebook->livelossplot) (0.2.3)\n",
      "Requirement already satisfied: bleach in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from nbconvert->notebook->livelossplot) (2.1.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from nbconvert->notebook->livelossplot) (1.4.2)\n",
      "Requirement already satisfied: testpath in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from nbconvert->notebook->livelossplot) (0.3.1)\n",
      "Requirement already satisfied: six in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from traitlets>=4.2.1->notebook->livelossplot) (1.11.0)\n",
      "Requirement already satisfied: decorator in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from traitlets>=4.2.1->notebook->livelossplot) (4.3.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from ipykernel->notebook->livelossplot) (6.4.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from nbformat->notebook->livelossplot) (2.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from jinja2->notebook->livelossplot) (1.0)\n",
      "Requirement already satisfied: setuptools in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->livelossplot) (39.1.0)\n",
      "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from bleach->nbconvert->notebook->livelossplot) (1.0.1)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (4.5.0)\n",
      "Requirement already satisfied: pickleshare in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.7.4)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.8.1)\n",
      "Requirement already satisfied: jedi>=0.10 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.12.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (1.0.15)\n",
      "Requirement already satisfied: backcall in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.1.0)\n",
      "Requirement already satisfied: webencodings in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->notebook->livelossplot) (0.5.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.5.2)\n",
      "Requirement already satisfied: parso>=0.2.0 in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.1.7)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "grxSpEFWza4c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WzYuL4iSza4k"
   },
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "-bioRbKEza4l",
    "outputId": "59b85d3c-aacc-4e62-dec6-429b8813dcf5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZIr-7KYza4r"
   },
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uS7Gq0ccza4s"
   },
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('/mnt/disks/user/project/PROJECT/Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('/mnt/disks/user/project/PROJECT/Project_data/val.csv').readlines())\n",
    "batch_size = 30 #experiment with the batch size\n",
    "num_of_images_in_video_frames = 16\n",
    "image_width = 120\n",
    "image_height = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "# function to plot n images using subplots\n",
    "def plot_image(images, captions=None, cmap=None ):\n",
    "    f, axes = plt.subplots(1, len(images), sharey=True)\n",
    "    f.set_figwidth(15)\n",
    "    for ax,image in zip(axes, images):\n",
    "        ax.imshow(image, cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWZ__MoNza4w"
   },
   "source": [
    "### Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKqyLG8neUx3"
   },
   "outputs": [],
   "source": [
    "def init_batch_data(batch_size):\n",
    "    batch_data = np.zeros((batch_size,num_of_images_in_video_frames,image_width,image_height,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "    batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "    return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ADGphO5etm1"
   },
   "outputs": [],
   "source": [
    "def read_batch_image(source_path, img_idx, folder_list, batch, batch_size, ):  \n",
    "    batch_data,batch_labels = init_batch_data(batch_size)\n",
    "    for folder in range(batch_size): # iterate over the batch_size\n",
    "        imgs = os.listdir(source_path+'/'+ folder_list[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "        for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "            image = imread(source_path+'/'+ folder_list[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "            \n",
    "            #crop the images and resize them. Note that the images are of 2 different shape \n",
    "            #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "            image = imresize(image, (image_width,image_height)).astype(np.float32)\n",
    "            norm2_image = image - np.min(image)/np.max(image) - np.min(image)\n",
    "            batch_data[folder,idx,:,:,0] = image[:, :, 0]/255 #normalise and feed in the image\n",
    "            batch_data[folder,idx,:,:,1] = image[:, :, 1]/255 #normalise and feed in the image\n",
    "            batch_data[folder,idx,:,:,2] = image[:, :, 2]/255 #normalise and feed in the image\n",
    "            \n",
    "        batch_labels[folder, int(folder_list[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "    return batch_data, batch_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEdJZLr_za41"
   },
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = [0,2,4,6,8,10,12,14,15,16,18,20,22,24,26,28]#[x for x in range(0, 30)]  #create a list of image numbers you want to use for a particular video\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            yield read_batch_image(source_path, img_idx, t, batch, batch_size) #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            yield read_batch_image(source_path, img_idx, t, batch, batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dwnmnKsza46"
   },
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Bj9QG2fBza48",
    "outputId": "379689d5-ba93-44d7-b7d9-79849e2e8c9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = '/mnt/disks/user/project/PROJECT/Project_data/train'\n",
    "val_path = '/mnt/disks/user/project/PROJECT/Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hk3YpS5aza5B"
   },
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4bkMGfK6za5D"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout,GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, GlobalMaxPooling3D\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "#write your model here\n",
    "nb_filters = [64,128]\n",
    "nb_dense = [256, 128, 5]\n",
    "\n",
    "# Input\n",
    "input_shape=(num_of_images_in_video_frames,image_width,image_height,3)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 kernel_initializer='he_uniform',\n",
    "                 input_shape=input_shape,\n",
    "                 activation = \"relu\",\n",
    "                 padding='same'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 kernel_initializer='he_uniform',\n",
    "                 activation = \"relu\",\n",
    "                 padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(GlobalMaxPooling3D())\n",
    "\n",
    "model.add(Dense(nb_dense[0], kernel_regularizer=l2(0.01),\n",
    "                 kernel_initializer='he_uniform',\n",
    "                 activation = \"relu\",))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2],\n",
    "                 activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ssQBc8Cgza5G"
   },
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "fAs0fJeTza5H",
    "outputId": "1c0cf61b-1156-4579-855f-d34d71fd31d9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 16, 120, 120, 64)  5248      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 8, 60, 60, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 8, 60, 60, 128)    221312    \n",
      "_________________________________________________________________\n",
      "global_max_pooling3d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 260,869\n",
      "Trainable params: 260,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "optimiser = Adam(lr=0.0008)\n",
    "#optimiser = Adam(lr=0.00086) #write your optimizerv .. (1) changed from 80 to 88\n",
    "#optimiser = SGD(lr=0.001, decay=1e-6, momentum=0.7, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9nE7pTepza5M"
   },
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNucJHpMza5R"
   },
   "outputs": [],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "#LR = ReduceLROnPlateau(monitor='val_loss', factor=0.20, patience=5, cooldown=1, verbose=1, mode='auto', min_delta=0.0001)\n",
    "#LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=12, cooldown=1, verbose=1)\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nr2jNOpZza5W"
   },
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(epoch, batch_sz):\n",
    "    train_generator = generator(train_path, train_doc, batch_sz)\n",
    "    val_generator = generator(val_path, val_doc, batch_sz)\n",
    "    if (num_train_sequences%batch_size) == 0:\n",
    "        steps_per_epoch = int(num_train_sequences/batch_sz)\n",
    "    else:\n",
    "        steps_per_epoch = (num_train_sequences//batch_sz) + 1\n",
    "\n",
    "    if (num_val_sequences%batch_size) == 0:\n",
    "        validation_steps = int(num_val_sequences/batch_sz)\n",
    "    else:\n",
    "        validation_steps = (num_val_sequences//batch_sz) + 1\n",
    "    \n",
    "    history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=epoch, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['categorical_accuracy'])\n",
    "    plt.plot(history.history['val_categorical_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TT3zYJslza5f"
   },
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_cnn_model(epoch=50, batch_sz=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  /mnt/disks/user/project/PROJECT/Project_data/val ; batch size = 10\n",
      "Source path =  /mnt/disks/user/project/PROJECT/Project_data/train ; batch size = 10\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 154s 2s/step - loss: 6.3968 - categorical_accuracy: 0.2433 - val_loss: 5.1005 - val_categorical_accuracy: 0.4727\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2316_16_24.941680/model-00001-6.40455-0.24585-5.10054-0.47273.h5\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - 15s 231ms/step - loss: 4.8051 - categorical_accuracy: 0.3433 - val_loss: 4.2697 - val_categorical_accuracy: 0.3273\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2316_16_24.941680/model-00002-4.80508-0.34328-4.26974-0.32727.h5\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - 16s 237ms/step - loss: 4.0061 - categorical_accuracy: 0.3980 - val_loss: 3.5417 - val_categorical_accuracy: 0.5091\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-12-2316_16_24.941680/model-00003-4.00611-0.39801-3.54174-0.50909.h5\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 16s 232ms/step - loss: 3.4851 - categorical_accuracy: 0.4179 - val_loss: 3.0600 - val_categorical_accuracy: 0.5273\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-12-2316_16_24.941680/model-00004-3.48513-0.41791-3.06000-0.52727.h5\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - 17s 248ms/step - loss: 3.0702 - categorical_accuracy: 0.4677 - val_loss: 2.7008 - val_categorical_accuracy: 0.5455\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-12-2316_16_24.941680/model-00005-3.07017-0.46766-2.70077-0.54545.h5\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - 16s 241ms/step - loss: 2.7888 - categorical_accuracy: 0.4726 - val_loss: 2.5442 - val_categorical_accuracy: 0.4727\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-12-2316_16_24.941680/model-00006-2.78884-0.47264-2.54423-0.47273.h5\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - 16s 238ms/step - loss: 2.4350 - categorical_accuracy: 0.5323 - val_loss: 2.3886 - val_categorical_accuracy: 0.4273\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-12-2316_16_24.941680/model-00007-2.43499-0.53234-2.38859-0.42727.h5\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - 15s 228ms/step - loss: 2.2141 - categorical_accuracy: 0.5522 - val_loss: 2.1679 - val_categorical_accuracy: 0.4364\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-12-2316_16_24.941680/model-00008-2.21414-0.55224-2.16787-0.43636.h5\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - 17s 254ms/step - loss: 2.1204 - categorical_accuracy: 0.5174 - val_loss: 1.8268 - val_categorical_accuracy: 0.6364\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-12-2316_16_24.941680/model-00009-2.12036-0.51741-1.82684-0.63636.h5\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - 15s 225ms/step - loss: 1.9164 - categorical_accuracy: 0.5672 - val_loss: 1.8139 - val_categorical_accuracy: 0.5818\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-12-2316_16_24.941680/model-00010-1.91644-0.56716-1.81387-0.58182.h5\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - 16s 232ms/step - loss: 1.7938 - categorical_accuracy: 0.6119 - val_loss: 1.8683 - val_categorical_accuracy: 0.4273\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-12-2316_16_24.941680/model-00011-1.79382-0.61194-1.86831-0.42727.h5\n",
      "Epoch 12/100\n",
      "67/67 [==============================] - 15s 231ms/step - loss: 1.6453 - categorical_accuracy: 0.6070 - val_loss: 1.6305 - val_categorical_accuracy: 0.6091\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-12-2316_16_24.941680/model-00012-1.64534-0.60697-1.63050-0.60909.h5\n",
      "Epoch 13/100\n",
      "67/67 [==============================] - 16s 235ms/step - loss: 1.5338 - categorical_accuracy: 0.6567 - val_loss: 1.4935 - val_categorical_accuracy: 0.6364\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-12-2316_16_24.941680/model-00013-1.53383-0.65672-1.49354-0.63636.h5\n",
      "Epoch 14/100\n",
      "67/67 [==============================] - 16s 237ms/step - loss: 1.5095 - categorical_accuracy: 0.5920 - val_loss: 1.6202 - val_categorical_accuracy: 0.4909\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-12-2316_16_24.941680/model-00014-1.50951-0.59204-1.62016-0.49091.h5\n",
      "Epoch 15/100\n",
      "67/67 [==============================] - 15s 228ms/step - loss: 1.4450 - categorical_accuracy: 0.6269 - val_loss: 1.4112 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-12-2316_16_24.941680/model-00015-1.44497-0.62687-1.41115-0.60000.h5\n",
      "Epoch 16/100\n",
      "67/67 [==============================] - 16s 235ms/step - loss: 1.3097 - categorical_accuracy: 0.6866 - val_loss: 1.5627 - val_categorical_accuracy: 0.5364\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-12-2316_16_24.941680/model-00016-1.30966-0.68657-1.56273-0.53636.h5\n",
      "Epoch 17/100\n",
      "67/67 [==============================] - 16s 236ms/step - loss: 1.2691 - categorical_accuracy: 0.6617 - val_loss: 1.1403 - val_categorical_accuracy: 0.7273\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-12-2316_16_24.941680/model-00017-1.26909-0.66169-1.14026-0.72727.h5\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - 16s 236ms/step - loss: 1.1082 - categorical_accuracy: 0.7363 - val_loss: 1.0515 - val_categorical_accuracy: 0.7455\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-12-2316_16_24.941680/model-00018-1.10819-0.73632-1.05151-0.74545.h5\n",
      "Epoch 19/100\n",
      "67/67 [==============================] - 16s 235ms/step - loss: 1.1538 - categorical_accuracy: 0.6965 - val_loss: 1.1632 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-12-2316_16_24.941680/model-00019-1.15379-0.69652-1.16317-0.70000.h5\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - 16s 239ms/step - loss: 1.1633 - categorical_accuracy: 0.6368 - val_loss: 1.1354 - val_categorical_accuracy: 0.6818\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-12-2316_16_24.941680/model-00020-1.16331-0.63682-1.13542-0.68182.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00039999998989515007.\n",
      "Epoch 21/100\n",
      "67/67 [==============================] - 15s 228ms/step - loss: 1.0563 - categorical_accuracy: 0.7065 - val_loss: 1.0172 - val_categorical_accuracy: 0.7273\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-12-2316_16_24.941680/model-00021-1.05631-0.70647-1.01719-0.72727.h5\n",
      "Epoch 22/100\n",
      "67/67 [==============================] - 16s 240ms/step - loss: 0.9023 - categorical_accuracy: 0.8109 - val_loss: 0.9928 - val_categorical_accuracy: 0.7545\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-12-2316_16_24.941680/model-00022-0.90231-0.81095-0.99279-0.75455.h5\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - 16s 234ms/step - loss: 0.8713 - categorical_accuracy: 0.7861 - val_loss: 0.9579 - val_categorical_accuracy: 0.7273\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-12-2316_16_24.941680/model-00023-0.87125-0.78607-0.95788-0.72727.h5\n",
      "Epoch 24/100\n",
      "67/67 [==============================] - 16s 234ms/step - loss: 0.8481 - categorical_accuracy: 0.8259 - val_loss: 0.9580 - val_categorical_accuracy: 0.7364\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-12-2316_16_24.941680/model-00024-0.84810-0.82587-0.95796-0.73636.h5\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - 16s 233ms/step - loss: 0.8239 - categorical_accuracy: 0.8209 - val_loss: 0.8537 - val_categorical_accuracy: 0.8273\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-12-2316_16_24.941680/model-00025-0.82389-0.82090-0.85366-0.82727.h5\n",
      "Epoch 26/100\n",
      "67/67 [==============================] - 15s 229ms/step - loss: 0.7054 - categorical_accuracy: 0.8806 - val_loss: 1.0234 - val_categorical_accuracy: 0.6182\n",
      "\n",
      "Epoch 00026: saving model to model_init_2019-12-2316_16_24.941680/model-00026-0.70539-0.88060-1.02335-0.61818.h5\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - 16s 243ms/step - loss: 0.8257 - categorical_accuracy: 0.7910 - val_loss: 0.8699 - val_categorical_accuracy: 0.7455\n",
      "\n",
      "Epoch 00027: saving model to model_init_2019-12-2316_16_24.941680/model-00027-0.82571-0.79104-0.86988-0.74545.h5\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00019999999494757503.\n",
      "Epoch 28/100\n",
      "67/67 [==============================] - 15s 226ms/step - loss: 0.7003 - categorical_accuracy: 0.8408 - val_loss: 0.8974 - val_categorical_accuracy: 0.7273\n",
      "\n",
      "Epoch 00028: saving model to model_init_2019-12-2316_16_24.941680/model-00028-0.70033-0.84080-0.89743-0.72727.h5\n",
      "Epoch 29/100\n",
      "67/67 [==============================] - 17s 248ms/step - loss: 0.6388 - categorical_accuracy: 0.8856 - val_loss: 0.9107 - val_categorical_accuracy: 0.7182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00029: saving model to model_init_2019-12-2316_16_24.941680/model-00029-0.63877-0.88557-0.91066-0.71818.h5\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 30/100\n",
      "67/67 [==============================] - 15s 227ms/step - loss: 0.6607 - categorical_accuracy: 0.8706 - val_loss: 0.8641 - val_categorical_accuracy: 0.7364\n",
      "\n",
      "Epoch 00030: saving model to model_init_2019-12-2316_16_24.941680/model-00030-0.66068-0.87065-0.86413-0.73636.h5\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - 16s 235ms/step - loss: 0.6556 - categorical_accuracy: 0.8657 - val_loss: 0.8802 - val_categorical_accuracy: 0.7273\n",
      "\n",
      "Epoch 00031: saving model to model_init_2019-12-2316_16_24.941680/model-00031-0.65559-0.86567-0.88019-0.72727.h5\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 32/100\n",
      "67/67 [==============================] - 16s 242ms/step - loss: 0.5677 - categorical_accuracy: 0.9104 - val_loss: 0.8203 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00032: saving model to model_init_2019-12-2316_16_24.941680/model-00032-0.56771-0.91045-0.82031-0.80000.h5\n",
      "Epoch 33/100\n",
      "67/67 [==============================] - 16s 232ms/step - loss: 0.6019 - categorical_accuracy: 0.9005 - val_loss: 0.8751 - val_categorical_accuracy: 0.7455\n",
      "\n",
      "Epoch 00033: saving model to model_init_2019-12-2316_16_24.941680/model-00033-0.60186-0.90050-0.87509-0.74545.h5\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - 16s 233ms/step - loss: 0.6083 - categorical_accuracy: 0.9005 - val_loss: 0.8381 - val_categorical_accuracy: 0.7364\n",
      "\n",
      "Epoch 00034: saving model to model_init_2019-12-2316_16_24.941680/model-00034-0.60831-0.90050-0.83813-0.73636.h5\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 35/100\n",
      "67/67 [==============================] - 15s 227ms/step - loss: 0.6130 - categorical_accuracy: 0.9005 - val_loss: 0.8246 - val_categorical_accuracy: 0.7636\n",
      "\n",
      "Epoch 00035: saving model to model_init_2019-12-2316_16_24.941680/model-00035-0.61303-0.90050-0.82462-0.76364.h5\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - 16s 236ms/step - loss: 0.5729 - categorical_accuracy: 0.9055 - val_loss: 0.8355 - val_categorical_accuracy: 0.7727\n",
      "\n",
      "Epoch 00036: saving model to model_init_2019-12-2316_16_24.941680/model-00036-0.57292-0.90547-0.83554-0.77273.h5\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 37/100\n",
      "67/67 [==============================] - 16s 235ms/step - loss: 0.5933 - categorical_accuracy: 0.8905 - val_loss: 0.8419 - val_categorical_accuracy: 0.7455\n",
      "\n",
      "Epoch 00037: saving model to model_init_2019-12-2316_16_24.941680/model-00037-0.59333-0.89055-0.84187-0.74545.h5\n",
      "Epoch 38/100\n",
      "67/67 [==============================] - 16s 232ms/step - loss: 0.5834 - categorical_accuracy: 0.9055 - val_loss: 0.8771 - val_categorical_accuracy: 0.7545\n",
      "\n",
      "Epoch 00038: saving model to model_init_2019-12-2316_16_24.941680/model-00038-0.58343-0.90547-0.87707-0.75455.h5\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 39/100\n",
      "67/67 [==============================] - 16s 234ms/step - loss: 0.5794 - categorical_accuracy: 0.9204 - val_loss: 0.8017 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00039: saving model to model_init_2019-12-2316_16_24.941680/model-00039-0.57937-0.92040-0.80173-0.80000.h5\n",
      "Epoch 40/100\n",
      "67/67 [==============================] - 15s 226ms/step - loss: 0.5692 - categorical_accuracy: 0.9005 - val_loss: 0.8104 - val_categorical_accuracy: 0.7727\n",
      "\n",
      "Epoch 00040: saving model to model_init_2019-12-2316_16_24.941680/model-00040-0.56924-0.90050-0.81045-0.77273.h5\n",
      "Epoch 41/100\n",
      "67/67 [==============================] - 16s 238ms/step - loss: 0.5443 - categorical_accuracy: 0.9353 - val_loss: 0.8376 - val_categorical_accuracy: 0.7818\n",
      "\n",
      "Epoch 00041: saving model to model_init_2019-12-2316_16_24.941680/model-00041-0.54435-0.93532-0.83764-0.78182.h5\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 42/100\n",
      "67/67 [==============================] - 15s 228ms/step - loss: 0.6094 - categorical_accuracy: 0.8806 - val_loss: 0.7697 - val_categorical_accuracy: 0.8182\n",
      "\n",
      "Epoch 00042: saving model to model_init_2019-12-2316_16_24.941680/model-00042-0.60941-0.88060-0.76969-0.81818.h5\n",
      "Epoch 43/100\n",
      "67/67 [==============================] - 15s 226ms/step - loss: 0.5410 - categorical_accuracy: 0.9502 - val_loss: 0.8747 - val_categorical_accuracy: 0.7545\n",
      "\n",
      "Epoch 00043: saving model to model_init_2019-12-2316_16_24.941680/model-00043-0.54103-0.95025-0.87469-0.75455.h5\n",
      "Epoch 44/100\n",
      "67/67 [==============================] - 16s 238ms/step - loss: 0.5586 - categorical_accuracy: 0.9104 - val_loss: 0.8224 - val_categorical_accuracy: 0.7636\n",
      "\n",
      "Epoch 00044: saving model to model_init_2019-12-2316_16_24.941680/model-00044-0.55858-0.91045-0.82240-0.76364.h5\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 45/100\n",
      "67/67 [==============================] - 16s 233ms/step - loss: 0.5824 - categorical_accuracy: 0.9204 - val_loss: 0.8347 - val_categorical_accuracy: 0.7818\n",
      "\n",
      "Epoch 00045: saving model to model_init_2019-12-2316_16_24.941680/model-00045-0.58238-0.92040-0.83469-0.78182.h5\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - 15s 228ms/step - loss: 0.6075 - categorical_accuracy: 0.9154 - val_loss: 0.7905 - val_categorical_accuracy: 0.7909\n",
      "\n",
      "Epoch 00046: saving model to model_init_2019-12-2316_16_24.941680/model-00046-0.60750-0.91542-0.79048-0.79091.h5\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - 16s 237ms/step - loss: 0.5737 - categorical_accuracy: 0.9204 - val_loss: 0.8424 - val_categorical_accuracy: 0.7636\n",
      "\n",
      "Epoch 00047: saving model to model_init_2019-12-2316_16_24.941680/model-00047-0.57368-0.92040-0.84236-0.76364.h5\n",
      "Epoch 48/100\n",
      "67/67 [==============================] - 15s 230ms/step - loss: 0.5295 - categorical_accuracy: 0.9502 - val_loss: 0.7578 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00048: saving model to model_init_2019-12-2316_16_24.941680/model-00048-0.52948-0.95025-0.75780-0.80000.h5\n",
      "Epoch 49/100\n",
      "67/67 [==============================] - 15s 223ms/step - loss: 0.5605 - categorical_accuracy: 0.9204 - val_loss: 0.8879 - val_categorical_accuracy: 0.7636\n",
      "\n",
      "Epoch 00049: saving model to model_init_2019-12-2316_16_24.941680/model-00049-0.56047-0.92040-0.88786-0.76364.h5\n",
      "Epoch 50/100\n",
      "67/67 [==============================] - 16s 233ms/step - loss: 0.5371 - categorical_accuracy: 0.9254 - val_loss: 0.7976 - val_categorical_accuracy: 0.7909\n",
      "\n",
      "Epoch 00050: saving model to model_init_2019-12-2316_16_24.941680/model-00050-0.53707-0.92537-0.79761-0.79091.h5\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "Epoch 51/100\n",
      "67/67 [==============================] - 16s 239ms/step - loss: 0.6099 - categorical_accuracy: 0.9055 - val_loss: 0.8299 - val_categorical_accuracy: 0.7727\n",
      "\n",
      "Epoch 00051: saving model to model_init_2019-12-2316_16_24.941680/model-00051-0.60986-0.90547-0.82990-0.77273.h5\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - 16s 232ms/step - loss: 0.6124 - categorical_accuracy: 0.9104 - val_loss: 0.8034 - val_categorical_accuracy: 0.7909\n",
      "\n",
      "Epoch 00052: saving model to model_init_2019-12-2316_16_24.941680/model-00052-0.61236-0.91045-0.80341-0.79091.h5\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "Epoch 53/100\n",
      "67/67 [==============================] - 16s 233ms/step - loss: 0.5197 - categorical_accuracy: 0.9502 - val_loss: 0.8538 - val_categorical_accuracy: 0.7636\n",
      "\n",
      "Epoch 00053: saving model to model_init_2019-12-2316_16_24.941680/model-00053-0.51967-0.95025-0.85378-0.76364.h5\n",
      "Epoch 54/100\n",
      "67/67 [==============================] - 15s 230ms/step - loss: 0.5920 - categorical_accuracy: 0.8756 - val_loss: 0.7985 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00054: saving model to model_init_2019-12-2316_16_24.941680/model-00054-0.59204-0.87562-0.79852-0.80000.h5\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "Epoch 55/100\n",
      "67/67 [==============================] - 16s 244ms/step - loss: 0.5740 - categorical_accuracy: 0.9104 - val_loss: 0.8354 - val_categorical_accuracy: 0.7545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00055: saving model to model_init_2019-12-2316_16_24.941680/model-00055-0.57398-0.91045-0.83542-0.75455.h5\n",
      "Epoch 56/100\n",
      "67/67 [==============================] - 15s 230ms/step - loss: 0.5334 - categorical_accuracy: 0.9353 - val_loss: 0.8036 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00056: saving model to model_init_2019-12-2316_16_24.941680/model-00056-0.53345-0.93532-0.80361-0.80000.h5\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 57/100\n",
      "67/67 [==============================] - 15s 225ms/step - loss: 0.5818 - categorical_accuracy: 0.8955 - val_loss: 0.8148 - val_categorical_accuracy: 0.7818\n",
      "\n",
      "Epoch 00057: saving model to model_init_2019-12-2316_16_24.941680/model-00057-0.58176-0.89552-0.81477-0.78182.h5\n",
      "Epoch 58/100\n",
      "67/67 [==============================] - 15s 226ms/step - loss: 0.6016 - categorical_accuracy: 0.9005 - val_loss: 0.8370 - val_categorical_accuracy: 0.7727\n",
      "\n",
      "Epoch 00058: saving model to model_init_2019-12-2316_16_24.941680/model-00058-0.60163-0.90050-0.83699-0.77273.h5\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 59/100\n",
      "67/67 [==============================] - 16s 233ms/step - loss: 0.5566 - categorical_accuracy: 0.9353 - val_loss: 0.8273 - val_categorical_accuracy: 0.7727\n",
      "\n",
      "Epoch 00059: saving model to model_init_2019-12-2316_16_24.941680/model-00059-0.55661-0.93532-0.82732-0.77273.h5\n",
      "Epoch 60/100\n",
      "67/67 [==============================] - 16s 233ms/step - loss: 0.5777 - categorical_accuracy: 0.8856 - val_loss: 0.8040 - val_categorical_accuracy: 0.7909\n",
      "\n",
      "Epoch 00060: saving model to model_init_2019-12-2316_16_24.941680/model-00060-0.57765-0.88557-0.80404-0.79091.h5\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 61/100\n",
      "67/67 [==============================] - 15s 225ms/step - loss: 0.5414 - categorical_accuracy: 0.9552 - val_loss: 0.8200 - val_categorical_accuracy: 0.7818\n",
      "\n",
      "Epoch 00061: saving model to model_init_2019-12-2316_16_24.941680/model-00061-0.54142-0.95522-0.82004-0.78182.h5\n",
      "Epoch 62/100\n",
      "67/67 [==============================] - 15s 229ms/step - loss: 0.5702 - categorical_accuracy: 0.9005 - val_loss: 0.8522 - val_categorical_accuracy: 0.7545\n",
      "\n",
      "Epoch 00062: saving model to model_init_2019-12-2316_16_24.941680/model-00062-0.57016-0.90050-0.85222-0.75455.h5\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "Epoch 63/100\n",
      "67/67 [==============================] - 16s 244ms/step - loss: 0.5471 - categorical_accuracy: 0.9453 - val_loss: 0.7763 - val_categorical_accuracy: 0.8182\n",
      "\n",
      "Epoch 00063: saving model to model_init_2019-12-2316_16_24.941680/model-00063-0.54705-0.94527-0.77632-0.81818.h5\n",
      "Epoch 64/100\n",
      "67/67 [==============================] - 15s 223ms/step - loss: 0.5624 - categorical_accuracy: 0.9254 - val_loss: 0.9091 - val_categorical_accuracy: 0.7182\n",
      "\n",
      "Epoch 00064: saving model to model_init_2019-12-2316_16_24.941680/model-00064-0.56241-0.92537-0.90907-0.71818.h5\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "Epoch 65/100\n",
      "67/67 [==============================] - 16s 233ms/step - loss: 0.5500 - categorical_accuracy: 0.9104 - val_loss: 0.7508 - val_categorical_accuracy: 0.8182\n",
      "\n",
      "Epoch 00065: saving model to model_init_2019-12-2316_16_24.941680/model-00065-0.55004-0.91045-0.75077-0.81818.h5\n",
      "Epoch 66/100\n",
      "67/67 [==============================] - 16s 232ms/step - loss: 0.6036 - categorical_accuracy: 0.9055 - val_loss: 0.8190 - val_categorical_accuracy: 0.7909\n",
      "\n",
      "Epoch 00066: saving model to model_init_2019-12-2316_16_24.941680/model-00066-0.60359-0.90547-0.81899-0.79091.h5\n",
      "Epoch 67/100\n",
      "67/67 [==============================] - 16s 237ms/step - loss: 0.5872 - categorical_accuracy: 0.9055 - val_loss: 0.8584 - val_categorical_accuracy: 0.7545\n",
      "\n",
      "Epoch 00067: saving model to model_init_2019-12-2316_16_24.941680/model-00067-0.58718-0.90547-0.85841-0.75455.h5\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.5258788677030566e-09.\n",
      "Epoch 68/100\n",
      "67/67 [==============================] - 15s 228ms/step - loss: 0.5697 - categorical_accuracy: 0.9104 - val_loss: 0.7594 - val_categorical_accuracy: 0.8182\n",
      "\n",
      "Epoch 00068: saving model to model_init_2019-12-2316_16_24.941680/model-00068-0.56967-0.91045-0.75941-0.81818.h5\n",
      "Epoch 69/100\n",
      "67/67 [==============================] - 15s 230ms/step - loss: 0.6282 - categorical_accuracy: 0.8706 - val_loss: 0.8787 - val_categorical_accuracy: 0.7545\n",
      "\n",
      "Epoch 00069: saving model to model_init_2019-12-2316_16_24.941680/model-00069-0.62821-0.87065-0.87873-0.75455.h5\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 7.629394338515283e-10.\n",
      "Epoch 70/100\n",
      "67/67 [==============================] - 16s 231ms/step - loss: 0.5287 - categorical_accuracy: 0.9303 - val_loss: 0.7844 - val_categorical_accuracy: 0.7909\n",
      "\n",
      "Epoch 00070: saving model to model_init_2019-12-2316_16_24.941680/model-00070-0.52865-0.93035-0.78445-0.79091.h5\n",
      "Epoch 71/100\n",
      "67/67 [==============================] - 16s 238ms/step - loss: 0.6067 - categorical_accuracy: 0.8955 - val_loss: 0.8039 - val_categorical_accuracy: 0.7818\n",
      "\n",
      "Epoch 00071: saving model to model_init_2019-12-2316_16_24.941680/model-00071-0.60674-0.89552-0.80385-0.78182.h5\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 3.8146971692576415e-10.\n",
      "Epoch 72/100\n",
      "67/67 [==============================] - 15s 227ms/step - loss: 0.5828 - categorical_accuracy: 0.9104 - val_loss: 0.8485 - val_categorical_accuracy: 0.7727\n",
      "\n",
      "Epoch 00072: saving model to model_init_2019-12-2316_16_24.941680/model-00072-0.58277-0.91045-0.84848-0.77273.h5\n",
      "Epoch 73/100\n",
      "67/67 [==============================] - 16s 234ms/step - loss: 0.5759 - categorical_accuracy: 0.9104 - val_loss: 0.8271 - val_categorical_accuracy: 0.7727\n",
      "\n",
      "Epoch 00073: saving model to model_init_2019-12-2316_16_24.941680/model-00073-0.57593-0.91045-0.82708-0.77273.h5\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.9073485846288207e-10.\n",
      "Epoch 74/100\n",
      "67/67 [==============================] - 15s 229ms/step - loss: 0.5522 - categorical_accuracy: 0.9104 - val_loss: 0.8561 - val_categorical_accuracy: 0.7727\n",
      "\n",
      "Epoch 00074: saving model to model_init_2019-12-2316_16_24.941680/model-00074-0.55219-0.91045-0.85614-0.77273.h5\n",
      "Epoch 75/100\n",
      "67/67 [==============================] - 16s 235ms/step - loss: 0.5439 - categorical_accuracy: 0.9055 - val_loss: 0.7414 - val_categorical_accuracy: 0.8182\n",
      "\n",
      "Epoch 00075: saving model to model_init_2019-12-2316_16_24.941680/model-00075-0.54393-0.90547-0.74136-0.81818.h5\n",
      "Epoch 76/100\n",
      "67/67 [==============================] - 15s 230ms/step - loss: 0.6261 - categorical_accuracy: 0.9104 - val_loss: 0.8669 - val_categorical_accuracy: 0.7545\n",
      "\n",
      "Epoch 00076: saving model to model_init_2019-12-2316_16_24.941680/model-00076-0.62612-0.91045-0.86694-0.75455.h5\n",
      "Epoch 77/100\n",
      "67/67 [==============================] - 15s 230ms/step - loss: 0.5234 - categorical_accuracy: 0.9502 - val_loss: 0.8023 - val_categorical_accuracy: 0.7909\n",
      "\n",
      "Epoch 00077: saving model to model_init_2019-12-2316_16_24.941680/model-00077-0.52336-0.95025-0.80233-0.79091.h5\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 9.536742923144104e-11.\n",
      "Epoch 78/100\n",
      "67/67 [==============================] - 16s 233ms/step - loss: 0.5682 - categorical_accuracy: 0.9154 - val_loss: 0.8203 - val_categorical_accuracy: 0.7818\n",
      "\n",
      "Epoch 00078: saving model to model_init_2019-12-2316_16_24.941680/model-00078-0.56819-0.91542-0.82033-0.78182.h5\n",
      "Epoch 79/100\n",
      "67/67 [==============================] - 15s 225ms/step - loss: 0.5905 - categorical_accuracy: 0.9005 - val_loss: 0.8215 - val_categorical_accuracy: 0.7818\n",
      "\n",
      "Epoch 00079: saving model to model_init_2019-12-2316_16_24.941680/model-00079-0.59048-0.90050-0.82148-0.78182.h5\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 4.768371461572052e-11.\n",
      "Epoch 80/100\n",
      "67/67 [==============================] - 16s 235ms/step - loss: 0.5606 - categorical_accuracy: 0.9204 - val_loss: 0.8204 - val_categorical_accuracy: 0.7727\n",
      "\n",
      "Epoch 00080: saving model to model_init_2019-12-2316_16_24.941680/model-00080-0.56059-0.92040-0.82041-0.77273.h5\n",
      "Epoch 81/100\n",
      "67/67 [==============================] - 15s 229ms/step - loss: 0.6021 - categorical_accuracy: 0.8856 - val_loss: 0.8267 - val_categorical_accuracy: 0.7727\n",
      "\n",
      "Epoch 00081: saving model to model_init_2019-12-2316_16_24.941680/model-00081-0.60209-0.88557-0.82672-0.77273.h5\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 2.384185730786026e-11.\n",
      "Epoch 82/100\n",
      "67/67 [==============================] - 16s 235ms/step - loss: 0.5376 - categorical_accuracy: 0.9254 - val_loss: 0.8175 - val_categorical_accuracy: 0.7727\n",
      "\n",
      "Epoch 00082: saving model to model_init_2019-12-2316_16_24.941680/model-00082-0.53764-0.92537-0.81750-0.77273.h5\n",
      "Epoch 83/100\n",
      "67/67 [==============================] - 15s 227ms/step - loss: 0.6034 - categorical_accuracy: 0.8955 - val_loss: 0.8256 - val_categorical_accuracy: 0.7909\n",
      "\n",
      "Epoch 00083: saving model to model_init_2019-12-2316_16_24.941680/model-00083-0.60344-0.89552-0.82561-0.79091.h5\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.192092865393013e-11.\n",
      "Epoch 84/100\n",
      "67/67 [==============================] - 16s 237ms/step - loss: 0.5267 - categorical_accuracy: 0.9254 - val_loss: 0.7864 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00084: saving model to model_init_2019-12-2316_16_24.941680/model-00084-0.52671-0.92537-0.78635-0.80000.h5\n",
      "Epoch 85/100\n",
      "67/67 [==============================] - 15s 221ms/step - loss: 0.6319 - categorical_accuracy: 0.8856 - val_loss: 0.8485 - val_categorical_accuracy: 0.7636\n",
      "\n",
      "Epoch 00085: saving model to model_init_2019-12-2316_16_24.941680/model-00085-0.63191-0.88557-0.84850-0.76364.h5\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 5.960464326965065e-12.\n",
      "Epoch 86/100\n",
      "67/67 [==============================] - 15s 231ms/step - loss: 0.5628 - categorical_accuracy: 0.9204 - val_loss: 0.7899 - val_categorical_accuracy: 0.7909\n",
      "\n",
      "Epoch 00086: saving model to model_init_2019-12-2316_16_24.941680/model-00086-0.56277-0.92040-0.78990-0.79091.h5\n",
      "Epoch 87/100\n",
      "67/67 [==============================] - 16s 239ms/step - loss: 0.5294 - categorical_accuracy: 0.9453 - val_loss: 0.8327 - val_categorical_accuracy: 0.7636\n",
      "\n",
      "Epoch 00087: saving model to model_init_2019-12-2316_16_24.941680/model-00087-0.52945-0.94527-0.83269-0.76364.h5\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 2.9802321634825324e-12.\n",
      "Epoch 88/100\n",
      "67/67 [==============================] - 15s 229ms/step - loss: 0.5783 - categorical_accuracy: 0.9055 - val_loss: 0.8317 - val_categorical_accuracy: 0.7909\n",
      "\n",
      "Epoch 00088: saving model to model_init_2019-12-2316_16_24.941680/model-00088-0.57829-0.90547-0.83170-0.79091.h5\n",
      "Epoch 89/100\n",
      "67/67 [==============================] - 16s 235ms/step - loss: 0.5701 - categorical_accuracy: 0.9104 - val_loss: 0.8371 - val_categorical_accuracy: 0.7818\n",
      "\n",
      "Epoch 00089: saving model to model_init_2019-12-2316_16_24.941680/model-00089-0.57005-0.91045-0.83706-0.78182.h5\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 1.4901160817412662e-12.\n",
      "Epoch 90/100\n",
      "67/67 [==============================] - 16s 240ms/step - loss: 0.5990 - categorical_accuracy: 0.8856 - val_loss: 0.8124 - val_categorical_accuracy: 0.7727\n",
      "\n",
      "Epoch 00090: saving model to model_init_2019-12-2316_16_24.941680/model-00090-0.59899-0.88557-0.81237-0.77273.h5\n",
      "Epoch 91/100\n",
      "67/67 [==============================] - 16s 239ms/step - loss: 0.5842 - categorical_accuracy: 0.9254 - val_loss: 0.8326 - val_categorical_accuracy: 0.7636\n",
      "\n",
      "Epoch 00091: saving model to model_init_2019-12-2316_16_24.941680/model-00091-0.58416-0.92537-0.83260-0.76364.h5\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 7.450580408706331e-13.\n",
      "Epoch 92/100\n",
      "67/67 [==============================] - 16s 236ms/step - loss: 0.5991 - categorical_accuracy: 0.8756 - val_loss: 0.8172 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00092: saving model to model_init_2019-12-2316_16_24.941680/model-00092-0.59910-0.87562-0.81719-0.80000.h5\n",
      "Epoch 93/100\n",
      "67/67 [==============================] - 16s 231ms/step - loss: 0.5660 - categorical_accuracy: 0.9254 - val_loss: 0.8126 - val_categorical_accuracy: 0.7727\n",
      "\n",
      "Epoch 00093: saving model to model_init_2019-12-2316_16_24.941680/model-00093-0.56596-0.92537-0.81262-0.77273.h5\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 3.7252902043531655e-13.\n",
      "Epoch 94/100\n",
      "67/67 [==============================] - 15s 231ms/step - loss: 0.5178 - categorical_accuracy: 0.9353 - val_loss: 0.8312 - val_categorical_accuracy: 0.7818\n",
      "\n",
      "Epoch 00094: saving model to model_init_2019-12-2316_16_24.941680/model-00094-0.51783-0.93532-0.83116-0.78182.h5\n",
      "Epoch 95/100\n",
      "67/67 [==============================] - 15s 224ms/step - loss: 0.6067 - categorical_accuracy: 0.9055 - val_loss: 0.8162 - val_categorical_accuracy: 0.7909\n",
      "\n",
      "Epoch 00095: saving model to model_init_2019-12-2316_16_24.941680/model-00095-0.60674-0.90547-0.81619-0.79091.h5\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1.8626451021765827e-13.\n",
      "Epoch 96/100\n",
      "67/67 [==============================] - 16s 233ms/step - loss: 0.5486 - categorical_accuracy: 0.9104 - val_loss: 0.7656 - val_categorical_accuracy: 0.7909\n",
      "\n",
      "Epoch 00096: saving model to model_init_2019-12-2316_16_24.941680/model-00096-0.54865-0.91045-0.76557-0.79091.h5\n",
      "Epoch 97/100\n",
      "67/67 [==============================] - 16s 238ms/step - loss: 0.5776 - categorical_accuracy: 0.9154 - val_loss: 0.8696 - val_categorical_accuracy: 0.7636\n",
      "\n",
      "Epoch 00097: saving model to model_init_2019-12-2316_16_24.941680/model-00097-0.57763-0.91542-0.86955-0.76364.h5\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 9.313225510882914e-14.\n",
      "Epoch 98/100\n",
      "67/67 [==============================] - 16s 245ms/step - loss: 0.5480 - categorical_accuracy: 0.9104 - val_loss: 0.8314 - val_categorical_accuracy: 0.7545\n",
      "\n",
      "Epoch 00098: saving model to model_init_2019-12-2316_16_24.941680/model-00098-0.54799-0.91045-0.83138-0.75455.h5\n",
      "Epoch 99/100\n",
      "67/67 [==============================] - 15s 230ms/step - loss: 0.5866 - categorical_accuracy: 0.9254 - val_loss: 0.8320 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00099: saving model to model_init_2019-12-2316_16_24.941680/model-00099-0.58658-0.92537-0.83198-0.80000.h5\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 4.656612755441457e-14.\n",
      "Epoch 100/100\n",
      "67/67 [==============================] - 15s 224ms/step - loss: 0.5497 - categorical_accuracy: 0.9254 - val_loss: 0.8002 - val_categorical_accuracy: 0.7818\n",
      "\n",
      "Epoch 00100: saving model to model_init_2019-12-2316_16_24.941680/model-00100-0.54974-0.92537-0.80016-0.78182.h5\n",
      "dict_keys(['val_loss', 'val_categorical_accuracy', 'loss', 'categorical_accuracy', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "build_cnn_model(epoch=100, batch_sz=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fap8hYLOza5k"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Dropout, Flatten, TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "rnn_batch_sz = 25\n",
    "rnn_num_epochs = 70\n",
    "rnn_num_of_images_in_video_frames = 15\n",
    "def rnn_init_batch_data(batch_size):\n",
    "    batch_data = np.zeros((batch_size,rnn_num_of_images_in_video_frames,image_width,image_height,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "    batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "    return batch_data, batch_labels\n",
    "def rnn_read_batch_image(source_path, img_idx, folder_list, batch, batch_size, ):  \n",
    "    batch_data,batch_labels = rnn_init_batch_data(batch_size)\n",
    "    for folder in range(batch_size): # iterate over the batch_size\n",
    "        imgs = os.listdir(source_path+'/'+ folder_list[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "        for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "            image = imread(source_path+'/'+ folder_list[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "            \n",
    "            #crop the images and resize them. Note that the images are of 2 different shape \n",
    "            #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "            image = imresize(image, (image_width,image_height)).astype(np.float32)\n",
    "            norm2_image = image - np.min(image)/np.max(image) - np.min(image)\n",
    "            batch_data[folder,idx,:,:,0] = norm2_image[:, :, 0] #normalise and feed in the image\n",
    "            batch_data[folder,idx,:,:,1] = norm2_image[:, :, 1] #normalise and feed in the image\n",
    "            batch_data[folder,idx,:,:,2] = norm2_image[:, :, 2] #normalise and feed in the image\n",
    "            \n",
    "        batch_labels[folder, int(folder_list[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "    return batch_data, batch_labels \n",
    "def rnn_generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = [0,2,4,6,8,10,12,14,16,18,20,22,24,26,28]  #create a list of image numbers you want to use for a particular video\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            yield rnn_read_batch_image(source_path, img_idx, t, batch, batch_size) #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            yield rnn_read_batch_image(source_path, img_idx, t, batch, batch_size)\n",
    "\n",
    "input_shape=(rnn_num_of_images_in_video_frames,image_width,image_height,3)\n",
    "train_generator = rnn_generator(train_path, train_doc, rnn_batch_sz)\n",
    "val_generator = rnn_generator(val_path, val_doc, rnn_batch_sz)\n",
    "model_name = 'model_init_conv_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "#LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001)\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001)\n",
    "\n",
    "callbacks_list = [checkpoint, LR]\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/rnn_batch_sz)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//rnn_batch_sz) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/rnn_batch_sz)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//rnn_batch_sz) + 1    \n",
    "    \n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(image_width,image_height,3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "#x.add(Dropout(0.5))\n",
    "features = Dense(128, activation='relu')(x)\n",
    "conv_model = Model(inputs=base_model.input, outputs=features)\n",
    "    \n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "        \n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(TimeDistributed(conv_model, input_shape=input_shape))\n",
    "model_rnn.add(GRU(64, return_sequences=True))\n",
    "model_rnn.add(GRU(32))\n",
    "model_rnn.add(Dropout(0.5))\n",
    "model_rnn.add(Dense(8, kernel_regularizer=l2(0.01),kernel_initializer='he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model_rnn.add(Dropout(0.25))\n",
    "model_rnn.add(Dense(5, kernel_regularizer=l2(0.01)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "\n",
    "#optimiser = optimizers.SGD(lr=0.001, decay=1e-4, momentum=0.7, nesterov=True)\n",
    "optimiser = Adam(lr=0.00085) #write your optimizer\n",
    "model_rnn.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_rnn.summary())\n",
    "\n",
    "\n",
    "\n",
    "history = model_rnn.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=rnn_num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_Nets_Project_Starter_Code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
